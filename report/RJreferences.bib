% put bibtex entries here!
@Book{plotly,
    author = {Carson Sievert},
    title = {{Interactive Web-Based Data Visualizatio}n with R, plotly, and shiny},
    publisher = {Chapman and Hall/CRC},
    year = {2020},
    isbn = {9781138331457},
    url = {https://plotly-r.com},
  }

@Manual{crosstalk,
  title = {{crosstalk}: Inter-Widget Interactivity for HTML Widgets},
  author = {Joe Cheng and Carson Sievert},
  year = {2021},
  note = {R package version 1.1.1},
  url = {https://CRAN.R-project.org/package=crosstalk},
}

@article{RJ-2021-050,
  author = {Earo Wang and Dianne Cook},
  title = {Conversations in time: interactive visualisation to explore
          structured temporal data},
  year = {2021},
  journal = {The R Journal},
  doi = {10.32614/RJ-2021-050},
  url = {https://journal.r-project.org/archive/2021/RJ-2021-050/index.html}
}

 @article{Kochanski_2021, title={A Simulation Model for Risk and Pricing Competition in the Retail Lending Market}, volume={71}, ISSN={2464-7683}, DOI={10.32065/CJEF.2021.02.01}, abstractNote={We propose a simulation model of the retail lending market with two types of agents: borrowers searching for low interest rates and lenders competing through risk-based pricing. We show that individual banks observe adverse selection, even if every lender applies the same pricing strategy and a credit scoring model of comparable discrimination power. Additionally, the model justifies the reverse-S shape of the response rate curve. According to the model, the benefits of even small increases in the discrimination power of credit scoring are substantial. This effect is more pronounced if the number of offers checked by the applicants before making a decision increases. The simulations illustrate the trade-off between profitability, market share, and credit loss rates. The profit-maximising strategy is to set interest rates slightly lower than the competition; the excessive price reduction turns out to be counterproductive. At the same time, there exists a niche for higher yield players.}, number={2}, journal={Czech Journal of Economics and Finance}, author={Kochański, Blazej}, year={2021}, month=oct, pages={96–118}, language={en} }

 @article{Vargha_Delaney_2000, title={A Critique and Improvement of the “CL” Common Language Effect Size Statistics of McGraw and Wong}, volume={25}, ISSN={1076-9986}, DOI={10.2307/1165329}, abstractNote={McGraw and Wong (1992) described an appealing index of effect size, called “CL”, which measures the difference between two populations in terms of the probability that a score sampled at random from the first population will be greater than a score sampled at random from the second. McGraw and Wong introduced this “common language effect size statistic” for normal distributions and then proposed an approximate estimation for any continuous distribution. In addition, they generalized “CL” to the n-group case, the correlated samples case, and the discrete values case. In the current paper a different generalization of “CL” called the A measure of stochastic superiority, is proposed, which may be directly applied for any discrete or continuous variable that is at least ordinally scaled. Exact methods for point and interval estimation as well as the significance tests of the A = .5 hypothesis are provided. New generalizations of “CL” are provided for the multi-group and correlated samples cases.}, number={2}, journal={Journal of Educational and Behavioral Statistics}, publisher={[American Educational Research Association, Sage Publications, Inc., American Statistical Association]}, author={Vargha, András and Delaney, Harold D.}, year={2000}, pages={101–132} }

 @article{Cliff_1993, address={US}, title={Dominance statistics: Ordinal analyses to answer ordinal questions}, volume={114}, ISSN={1939-1455}, DOI={10.1037/0033-2909.114.3.494}, abstractNote={Much behavioral research involves comparing the central tendencies of different groups, or of the same Ss under different conditions, and the usual analysis is some form of mean comparison. This article suggests that an ordinal statistic, d, is often more appropriate. d compares the number of times a score from one group or condition is higher than one from the other, compared with the reverse. Compared to mean comparisons, d is more robust and equally or more powerful; it is invariant under transformation; and it often conforms more closely to the experimeter’s research hypothesis. It is suggested that inferences from d be based on sample estimates of its variance rather than on the more traditional assumption of identical distributions. The statistic is extended to simple repeated measures designs, and ways of extending its use to more complex designs are suggested. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}, number={3}, journal={Psychological Bulletin}, publisher={American Psychological Association}, author={Cliff, Norman}, year={1993}, pages={494–509} }

 @article{Idczak_2019, title={Remarks on Statistical Measures for Assessing Quality of Scoring Models}, volume={4}, rights={Copyright (c) 2019}, ISSN={2353-7663}, DOI={10.18778/0208-6018.343.02}, abstractNote={Granting a credit product has always been at the heart of banking. Simultaneously, banks are obligated to assess the borrower’s credit risk. Apart from creditworthiness, to grant a credit product, banks are using credit scoring more and more often. Scoring models, which are an essential part of credit scoring, are being developed in order to select those clients who will repay their debt. For lenders, high effectiveness of selection based on the scoring model is the primary attribute, so it is crucial to gauge its statistical quality. Several textbooks regarding assessing statistical quality of scoring models are available, there is however no full consistency between names and definitions of particular measures. In this article, the most common statistical measures for assessing quality of scoring models, such as the pseudo Gini index, Kolmogorov‑Smirnov statistic, and concentration curve are reviewed and their statistical characteristics are discussed. Furthermore, the author proposes the application of the well‑known distribution similarity index as a measure of discriminatory power of scoring models. The author also attempts to standardise names and formulas for particular measures in order to finally contrast them in a comparative analysis of credit scoring models.}, number={343343}, journal={Acta Universitatis Lodziensis. Folia Oeconomica}, author={Idczak, Adam Piotr}, year={2019}, month=sept, pages={21–38}, language={en} }

 @article{Bamber_1975, title={The area above the ordinal dominance graph and the area below the receiver operating characteristic graph}, volume={12}, rights={https://www.elsevier.com/tdm/userlicense/1.0/}, ISSN={00222496}, DOI={10.1016/0022-2496(75)90001-2}, number={4}, journal={Journal of Mathematical Psychology}, author={Bamber, Donald}, year={1975}, month=nov, pages={387–415}, language={en} }

 @article{Harrell_Califf, title={Evaluating the Yield of Medical Tests}, author={Harrell, Frank E and Califf, Robert M}, language={en} }

 @article{Hanley_McNeil_1982, title={The meaning and use of the area under a receiver operating characteristic (ROC) curve.}, volume={143}, ISSN={0033-8419}, DOI={10.1148/radiology.143.1.7063747}, abstractNote={A representation and interpretation of the area under a receiver operating characteristic (ROC) curve obtained by the “rating” method, or by mathematical predictions based on patient characteristics, is presented. It is shown that in such a setting the area represents the probability that a randomly chosen diseased subject is (correctly) rated or ranked with greater suspicion than a randomly chosen non-diseased subject. Moreover, this probability of a correct ranking is the same quantity that is estimated by the already well-studied nonparametric Wilcoxon statistic. These two relationships are exploited to (a) provide rapid closed-form expressions for the approximate magnitude of the sampling variability, i.e., standard error that one uses to accompany the area under a smoothed ROC curve, (b) guide in determining the size of the sample required to provide a sufficiently reliable estimate of this area, and (c) determine how large sample sizes should be to ensure that one can statistically detect differences in the accuracy of diagnostic techniques.}, number={1}, journal={Radiology}, publisher={Radiological Society of North America}, author={Hanley, J A and McNeil, B J}, year={1982}, month=apr, pages={29–36} }

 @article{Engelmann_Hayden_Tasche_2003, title={Measuring the Discriminative Power of Rating Systems}, ISSN={1556-5068}, url={https://www.ssrn.com/abstract=2793951}, DOI={10.2139/ssrn.2793951}, abstractNote={Assessing the discriminative power of rating systems is an important question to banks and to regulators. In this article we analyze the Cumulative Accuracy Proﬁle (CAP) and the Receiver Operating Characteristic (ROC) which are both commonly used in practice. We give a test-theoretic interpretation for the concavity of the CAP and the ROC curve and demonstrate how this observation can be used for more efﬁciently exploiting the informational contents of accounting ratios. Furthermore, we show that two popular summary statistics of these concepts, namely the Accuracy Ratio and the area under the ROC curve, contain the same information and we analyse the statistical properties of these measures. We show in detail how to identify accounting ratios with high discriminative power, how to calculate conﬁdence intervals for the area below the ROC curve, and how to test if two rating models validated on the same data set are different. All concepts are illustrated by applications to real data.}, journal={SSRN Electronic Journal}, author={Engelmann, Bernd and Hayden, Evelyn and Tasche, Dirk}, year={2003}, language={en} }

 @article{Newson_2002, title={Parameters behind “Nonparametric” Statistics: Kendall’s tau, Somers’ D and Median Differences}, volume={2}, rights={https://journals.sagepub.com/page/policies/text-and-data-mining-license}, ISSN={1536-867X, 1536-8734}, DOI={10.1177/1536867X0200200103}, abstractNote={So-called “non-parametric” statistical methods are often in fact based on population parameters, which can be estimated (with conﬁdence limits) using the corresponding sample statistics. This article reviews the uses of three such parameters, namely Kendall’s τa, Somers’ D and the Hodges-Lehmann median diﬀerence. Conﬁdence intervals for these are demonstrated using the somersd package. It is argued that conﬁdence limits for these parameters, and their diﬀerences, are more informative than the traditional practice of reporting only P -values. These three parameters are also important in deﬁning other tests and parameters, such as the Wilcoxon test, the area under the receiver operating characteristic (ROC) curve, Harrell’s C, and the Theil median slope.}, number={1}, journal={The Stata Journal: Promoting communications on statistics and Stata}, author={Newson, Roger}, year={2002}, month=mar, pages={45–64}, language={en} }

 @article{Somers_1962, title={A New Asymmetric Measure of Association for Ordinal Variables}, volume={27}, ISSN={00031224}, DOI={10.2307/2090408}, number={6}, journal={American Sociological Review}, author={Somers, Robert H.}, year={1962}, month=dec, pages={799}, language={en} }

 @article{Austin_Steyerberg_2012, title={Interpreting the concordance statistic of a logistic regression model: relation to the variance and odds ratio of a continuous explanatory variable}, volume={12}, rights={http://creativecommons.org/licenses/by/2.0}, ISSN={1471-2288}, DOI={10.1186/1471-2288-12-82}, abstractNote={Background: When outcomes are binary, the c-statistic (equivalent to the area under the Receiver Operating Characteristic curve) is a standard measure of the predictive accuracy of a logistic regression model.
Methods: An analytical expression was derived under the assumption that a continuous explanatory variable follows a normal distribution in those with and without the condition. We then conducted an extensive set of Monte Carlo simulations to examine whether the expressions derived under the assumption of binormality allowed for accurate prediction of the empirical c-statistic when the explanatory variable followed a normal distribution in the combined sample of those with and without the condition. We also examine the accuracy of the predicted cstatistic when the explanatory variable followed a gamma, log-normal or uniform distribution in combined sample of those with and without the condition.
Results: Under the assumption of binormality with equality of variances, the c-statistic follows a standard normal cumulative distribution function with dependence on the product of the standard deviation of the normal components (reflecting more heterogeneity) and the log-odds ratio (reflecting larger effects). Under the assumption of binormality with unequal variances, the c-statistic follows a standard normal cumulative distribution function with dependence on the standardized difference of the explanatory variable in those with and without the condition. In our Monte Carlo simulations, we found that these expressions allowed for reasonably accurate prediction of the empirical c-statistic when the distribution of the explanatory variable was normal, gamma, log-normal, and uniform in the entire sample of those with and without the condition.
Conclusions: The discriminative ability of a continuous explanatory variable cannot be judged by its odds ratio alone, but always needs to be considered in relation to the heterogeneity of the population.}, number={1}, journal={BMC Medical Research Methodology}, author={Austin, Peter C and Steyerberg, Ewout W}, year={2012}, month=dec, pages={82}, language={en} }

 @article{Bais_Van_Der_Neut_2022, title={Adapting the Robust Effect Size Cliff’s Delta to Compare Behaviour Profiles}, rights={Creative Commons Attribution Non Commercial 4.0 International}, DOI={10.18148/SRM/2022.V16I2.7908}, abstractNote={Cliff’s Delta is a non-parametric effect size that is based on data observations. In this paper, we introduce an adaptation of Cliff’s Delta in order to compare behaviour profiles. Behaviour profiles are density distributions in which survey answer behaviour is summarized for specific groups of respondents or items. Such profiles are useful, as they take into account the varying number of survey items that is filled out per respondent due to filter questions. By the adapted Cliff’s Delta, two subgroups of respondents (for instance higher and lower educated respondents) can be compared on the occurrence of specific answer behaviour (for instance giving ‘don’t know’-answers). By means of simulations, we show that the adapted profile-based Cliff’s Delta converges towards the original observation-based Cliff’s Delta as the number of items that is filled out by respondents increases. We conclude that the profile-based Cliff’s Delta is a solid and conservative statistic that is both useful and advantageous to compare behaviour profiles. We close with various data examples to illustrate its broad usefulness and by discussing potential difficulty in using the profile-based Cliff’s Delta.}, journal={Survey Research Methods}, publisher={Survey Research Methods}, author={Bais, Frank and Van Der Neut, Joost}, year={2022}, month=dec, pages={329-352 Pages}, language={en} }

 @article{Brunner_Munzel_Puri_2002, title={The multivariate nonparametric Behrens–Fisher problem}, volume={108}, rights={https://www.elsevier.com/tdm/userlicense/1.0/}, ISSN={03783758}, DOI={10.1016/S0378-3758(02)00269-0}, abstractNote={In this paper, we consider the multivariate case of the so-called nonparametric Behrens–Fisher problem where two samples with independent multivariate observations are given and the equality of the marginal distribution functions under the hypothesis in the two groups is not assumed. Moreover, we do not require the continuity of the marginal distribution functions so that data with ties and, particularly, multivariate-ordered categorical data are covered by this model. A multivariate relative treatment e3ect is de4ned which can be estimated by using the mid-ranks of the observations within each component and we derive the asymptotic distribution of this estimator. Moreover, the unknown asymptotic covariance matrix of the centered vector of the estimated relative treatment e3ects is estimated and its L2-consistency is proved. To test the hypothesis of no treatment e3ect, we consider the rank version of the Wald-type statistic (as used in Puri and Sen, Nonparametric Methods in Multivariate Analysis, Wiley, New York, 1971) and the rank version of the ANOVA-type statistic which was suggested by Brunner et al. [J. Amer. Statist. Assoc. 92 (1997) 1494–1502] for univariate nonparametric models. Simulations show that the ANOVA-type statistic appears to maintain the pre-assigned level of the test quite accurately (even for rather small sample sizes) while the Wald-type statistic leads to more or less liberal decisions. Regarding the power, none of the two statistics is uniformly superior to the other.}, number={1–2}, journal={Journal of Statistical Planning and Inference}, author={Brunner, Edgar and Munzel, Ullrich and Puri, Madan L.}, year={2002}, month=nov, pages={37–53}, language={en} }

 @article{Hand_Till, title={A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems}, abstractNote={The area under the ROC curve, or the equivalent Gini index, is a widely used measure of performance of supervised classiﬁcation rules. It has the attractive property that it side-steps the need to specify the costs of the different kinds of misclassiﬁcation. However, the simple form is only applicable to the case of two classes. We extend the deﬁnition to the case of more than two classes by averaging pairwise comparisons. This measure reduces to the standard form in the two class case. We compare its properties with the standard measure of proportion correct and an alternative deﬁnition of proportion correct based on pairwise comparison of classes for a simple artiﬁcial case and illustrate its application on eight data sets. On the data sets we examined, the measures produced similar, but not identical results, reﬂecting the different aspects of performance that they were measuring. Like the area under the ROC curve, the measure we propose is useful in those many situations where it is impossible to give costs for the different kinds of misclassiﬁcation.}, author={Hand, David J and Till, Robert J}, language={en} }

 @article{Harrell_Califf_Pryor_Lee_Rosati_1982, title={Evaluating the Yield of Medical Tests}, volume={247}, ISSN={0098-7484}, DOI={10.1001/jama.1982.03320430047030}, abstractNote={A method is presented for evaluating the amount of information a medical test provides about individual patients. Emphasis is placed on the role of a test in the evaluation of patients with a chronic disease. In this context, the yield of a test is best interpreted by analyzing the prognostic information it furnishes. Information from the history, physical examination, and routine procedures should be used in assessing the yield of a new test. As an example, the method is applied to the use of the treadmill exercise test in evaluating the prognosis of patients with suspected coronary artery disease. The treadmill test is shown to provide surprisingly little prognostic information beyond that obtained from basic clinical measurements.(JAMA 1982;247:2543-2546)}, number={18}, journal={JAMA}, author={Harrell, Frank E., Jr and Califf, Robert M. and Pryor, David B. and Lee, Kerry L. and Rosati, Robert A.}, year={1982}, month=may, pages={2543–2546} }

 @article{McGraw_Wong_1992, address={US}, title={A common language effect size statistic}, volume={111}, ISSN={1939-1455}, DOI={10.1037/0033-2909.111.2.361}, abstractNote={Some of the shortcomings in interpretability and generalizability of the effect size statistics currently available to researchers can be overcome by a statistic that expresses how often a score sampled from one distribution will be greater than a score sampled from another distribution. The statistic, the common language effect size indicator, is easily calculated from sample means and variances (or from proportions in the case of nominal-level data). It can be used for expressing the effect observed in both independent and related sample designs and in both 2-group and n-group designs. Empirical tests show it to be robust to violations of the normality assumption, particularly when the variances in the 2 parent distributions are equal. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}, number={2}, journal={Psychological Bulletin}, publisher={American Psychological Association}, author={McGraw, Kenneth O. and Wong, S. P.}, year={1992}, pages={361–365} }

 @article{LeDell_Petersen_Van_Der_Laan_2015, title={Computationally efficient confidence intervals for cross-validated area under the ROC curve estimates}, volume={9}, ISSN={1935-7524}, url={https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-9/issue-1/Computationally-efficient-confidence-intervals-for-cross-validated-area-under-the/10.1214/15-EJS1035.full}, DOI={10.1214/15-EJS1035}, abstractNote={In binary classification problems, the area under the ROC curve (AUC) is commonly used to evaluate the performance of a prediction model. Often, it is combined with cross-validation in order to assess how the results will generalize to an independent data set. In order to evaluate the quality of an estimate for cross-validated AUC, we obtain an estimate of its variance. For massive data sets, the process of generating a single performance estimate can be computationally expensive. Additionally, when using a complex prediction method, the process of cross-validating a predictive model on even a relatively small data set can still require a large amount of computation time. Thus, in many practical settings, the bootstrap is a computationally intractable approach to variance estimation. As an alternative to the bootstrap, we demonstrate a computationally efficient influence curve based approach to obtaining a variance estimate for cross-validated AUC.}, number={1}, journal={Electronic Journal of Statistics}, author={LeDell, Erin and Petersen, Maya and Van Der Laan, Mark}, year={2015}, month=jan, language={en} }

 @article{Noma_Matsushima_Ishii_2021, title={Confidence interval for the AUC of SROC curve and some related methods using bootstrap for meta-analysis of diagnostic accuracy studies}, volume={7}, ISSN={2373-7484}, DOI={10.1080/23737484.2021.1894408}, abstractNote={The area under the curve (AUC) of summary receiver operating characteristic (SROC) curve is a primary statistical outcome for meta-analysis of diagnostic test accuracy studies (DTA). However, its confidence interval has not been reported in most of DTA meta-analyses, because no certain methods and statistical packages have been provided. In this article, we provide a bootstrap algorithm for computing the confidence interval of the AUC. Also, using the bootstrap framework, we can conduct a bootstrap test for assessing significance of the difference of AUCs for two diagnostic tests. In addition, we provide an influence diagnostic method based on the AUC by leave-one-study-out analyses. We present illustrative examples using two DTA met-analyses for diagnostic tests of cervical cancer and asthma. We also developed an easy-to-handle R package dmetatools for these computations. The various quantitative evidence provided by these methods certainly supports the interpretations and precise evaluations of statistical evidence of DTA meta-analyses.}, number={3}, journal={Communications in Statistics: Case Studies, Data Analysis and Applications}, author={Noma, Hisashi and Matsushima, Yuki and Ishii, Ryota}, year={2021}, month=july, pages={344–358}, language={en} }

 @article{Bandos_Rockette_Gur_2006, title={A Permutation Test for Comparing ROC Curves in Multireader Studies}, volume={13}, rights={https://www.elsevier.com/tdm/userlicense/1.0/}, ISSN={10766332}, DOI={10.1016/j.acra.2005.12.012}, number={4}, journal={Academic Radiology}, author={Bandos, Andriy I. and Rockette, Howard E. and Gur, David}, year={2006}, month=apr, pages={414–420}, language={en} }

 @article{Pauly_Asendorf_Konietschke_2016, title={Permutation‐based inference for the AUC: A unified approach for continuous and discontinuous data}, volume={58}, rights={http://onlinelibrary.wiley.com/termsAndConditions#vor}, ISSN={0323-3847, 1521-4036}, DOI={10.1002/bimj.201500105}, abstractNote={We investigate rank‐based studentized permutation methods for the nonparametric Behrens–Fisher problem, that is, inference methods for the area under the ROC curve. We hereby prove that the studentized permutation distribution of the Brunner‐Munzel rank statistic is asymptotically standard normal, even under the alternative. Thus, incidentally providing the hitherto missing theoretical foundation for the Neubert and Brunner studentized permutation test. In particular, we do not only show its consistency, but also that confidence intervals for the underlying treatment effects can be computed by inverting this permutation test. In addition, we derive permutation‐based range‐preserving confidence intervals. Extensive simulation studies show that the permutation‐based confidence intervals appear to maintain the preassigned coverage probability quite accurately (even for rather small sample sizes). For a convenient application of the proposed methods, a freely available software package for the statistical software R has been developed. A real data example illustrates the application.}, number={6}, journal={Biometrical Journal}, author={Pauly, Markus and Asendorf, Thomas and Konietschke, Frank}, year={2016}, month=nov, pages={1319–1337}, language={en} }

 @article{Janitza_Strobl_Boulesteix_2013, title={An AUC-based permutation variable importance measure for random forests}, volume={14}, rights={http://creativecommons.org/licenses/by/2.0}, ISSN={1471-2105}, DOI={10.1186/1471-2105-14-119}, abstractNote={Background: The random forest (RF) method is a commonly used tool for classification with high dimensional data as well as for ranking candidate predictors based on the so-called random forest variable importance measures (VIMs). However the classification performance of RF is known to be suboptimal in case of strongly unbalanced data, i.e. data where response class sizes differ considerably. Suggestions were made to obtain better classification performance based either on sampling procedures or on cost sensitivity analyses. However to our knowledge the performance of the VIMs has not yet been examined in the case of unbalanced response classes. In this paper we explore the performance of the permutation VIM for unbalanced data settings and introduce an alternative permutation VIM based on the area under the curve (AUC) that is expected to be more robust towards class imbalance.
Results: We investigated the performance of the standard permutation VIM and of our novel AUC-based permutation VIM for different class imbalance levels using simulated data and real data. The results suggest that the new AUC-based permutation VIM outperforms the standard permutation VIM for unbalanced data settings while both permutation VIMs have equal performance for balanced data settings.
Conclusions: The standard permutation VIM loses its ability to discriminate between associated predictors and predictors not associated with the response for increasing class imbalance. It is outperformed by our new AUC-based permutation VIM for unbalanced data settings, while the performance of both VIMs is very similar in the case of balanced classes. The new AUC-based VIM is implemented in the R package party for the unbiased RF variant based on conditional inference trees. The codes implementing our study are available from the companion website: http://www.ibe.med.uni-muenchen.de/organisation/mitarbeiter/070_drittmittel/janitza/index.html.}, number={1}, journal={BMC Bioinformatics}, author={Janitza, Silke and Strobl, Carolin and Boulesteix, Anne-Laure}, year={2013}, month=dec, pages={119}, language={en} }

@Article{Biecek_2018,
    title = {DALEX: Explainers for Complex Predictive Models in R},
    author = {Przemyslaw Biecek},
    journal = {Journal of Machine Learning Research},
    year = {2018},
    volume = {19},
    pages = {1-5},
    number = {84},
    url = {https://jmlr.org/papers/v19/18-416.html},
  }
  
 @article{Yang_Ying_2023, title={AUC Maximization in the Era of Big Data and AI: A Survey}, volume={55}, ISSN={0360-0300, 1557-7341}, DOI={10.1145/3554729}, abstractNote={Area under the ROC curve, a.k.a. AUC, is a measure of choice for assessing the performance of a classifier for imbalanced data. AUC maximization refers to a learning paradigm that learns a predictive model by directly maximizing its AUC score. It has been studied for more than two decades dating back to late 90s and a huge amount of work has been devoted to AUC maximization since then. Recently, stochastic AUC maximization for big data and deep AUC maximization (DAM) for deep learning have received increasing attention and yielded dramatic impact for solving real-world problems. However, to the best our knowledge there is no comprehensive survey of related works for AUC maximization. This paper aims to address the gap by reviewing the literature in the past two decades. We not only give a holistic view of the literature but also present detailed explanations and comparisons of different papers from formulations to algorithms and theoretical guarantees. We also identify and discuss remaining and emerging issues for DAM, and provide suggestions on topics for future work. CCS Concepts: • Computing methodologies → Machine learning algorithms; • Theory of computation → Continuous optimization; Stochastic control and optimization.}, number={8}, journal={ACM Computing Surveys}, author={Yang, Tianbao and Ying, Yiming}, year={2023}, month=aug, pages={1–37}, language={en} }

 @article{Kochanski_2021, title={A Simulation Model for Risk and Pricing Competition in the Retail Lending Market}, volume={71}, ISSN={2464-7683}, DOI={10.32065/CJEF.2021.02.01}, abstractNote={We propose a simulation model of the retail lending market with two types of agents: borrowers searching for low interest rates and lenders competing through risk-based pricing. We show that individual banks observe adverse selection, even if every lender applies the same pricing strategy and a credit scoring model of comparable discrimination power. Additionally, the model justifies the reverse-S shape of the response rate curve. According to the model, the benefits of even small increases in the discrimination power of credit scoring are substantial. This effect is more pronounced if the number of offers checked by the applicants before making a decision increases. The simulations illustrate the trade-off between profitability, market share, and credit loss rates. The profit-maximising strategy is to set interest rates slightly lower than the competition; the excessive price reduction turns out to be counterproductive. At the same time, there exists a niche for higher yield players.}, number={2}, journal={Czech Journal of Economics and Finance}, author={Kochanski, Blazej}, year={2021}, month=oct, pages={96–118}, language={en} }

 @article{Kochański_2022, title={Which Curve Fits Best: Fitting ROC Curve Models to Empirical Credit-Scoring Data}, volume={10}, rights={https://creativecommons.org/licenses/by/4.0/}, ISSN={2227-9091}, DOI={10.3390/risks10100184}, abstractNote={In the practice of credit-risk management, the models for receiver operating characteristic (ROC) curves are helpful in describing the shape of an ROC curve, estimating the discriminatory power of a scorecard, and generating ROC curves without underlying data. The primary purpose of this study is to review the ROC curve models proposed in the literature, primarily in biostatistics, and to ﬁt them to actual credit-scoring ROC data in order to determine which models could be used in credit-risk-management practice. We list several theoretical models for an ROC curve and describe them in the credit-scoring context. The model list includes the binormal, bigamma, bibeta, bilogistic, power, and bifractal curves. The models are then tested against empirical credit-scoring ROC data from publicly available presentations and papers, as well as from European retail lending institutions. Except for the power curve, all the presented models ﬁt the data quite well. However, based on the results and other favourable properties, it is suggested that the binormal curve is the preferred choice for modelling credit-scoring ROC curves.}, number={10}, journal={Risks}, author={Kochański, Błażej}, year={2022}, month=sept, pages={184}, language={en} }

